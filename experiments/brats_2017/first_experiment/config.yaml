# wandb parameters
# project: segfmr3d
# wandb_parameters:
#   mode: "offline" # set this to "online" if you want to log to wandb
#   entity: pcvlab
#   group: brats2017
#   name: segformer3d_adamw_batch2_diceloss
#   resume: False
#   tags: ["pcvlab", "dice", "b0_model", "adamw"]

# wandb parameters
project: segfmr3d
wandb_parameters:
  mode: "online"   # switch to online so logs sync to the cloud
  entity: alihoussenaly-isae-supaero   # W&B username
  group: brats2017    # optional grouping for runs
  name: segformer3d_adamw_batch2_diceloss
  resume: "must"   # automatically resume if run with same name exists
  id: "vybwzlw7"  # unique id to identify the run
  tags: ["segformer3d", "brats2017", "adamw"]

# model parameters
model_name: segformer3d
model_parameters:
    in_channels: 4
    sr_ratios: [4, 2, 1, 1]
    embed_dims: [32, 64, 160, 256]
    patch_kernel_size: [7, 3, 3, 3]
    patch_stride: [4, 2, 2, 2]
    patch_padding: [3, 1, 1, 1]
    mlp_ratios: [4, 4, 4, 4]
    num_heads: [1, 2, 5, 8]
    depths: [2, 2, 2, 2]
    num_classes: 3
    decoder_dropout: 0.0
    decoder_head_embedding_dim: 256

# loss function
loss_fn:
  loss_type: "dice"
  loss_args: None

# optimizer
optimizer:
  optimizer_type: "adamw"
  optimizer_args:
    lr: 0.0001
    weight_decay: 0.01

# schedulers
warmup_scheduler:
  enabled: True # should be always true
  warmup_epochs: 5 # Initial : 20 // Now : 5 // For testing purpose

train_scheduler:
  scheduler_type: 'cosine_annealing_wr'
  scheduler_args:
    t_0_epochs: 400
    t_mult: 1
    min_lr: 0.000006

# (Not fully implemented yet) eponential moving average
ema:
  enabled: False
  ema_decay: 0.999
  val_ema_every: 1

sliding_window_inference:
  sw_batch_size: 6 # Initial : 4 // Now : 6 // faster validation but more GPU memory usage
  roi: [128, 128, 128]

# gradient clipping (not implemented yet)
clip_gradients:
  enabled: False
  clip_gradients_value: 0.1

# training hyperparameters
training_parameters:
  seed: 42
  num_epochs: 100 # Initial : 800 // Now : 100 // For testing purpose
  cutoff_epoch: 400
  load_optimizer: False
  print_every: 200
  calculate_metrics: True
  grad_accumulate_steps: 1 # default: 1
  checkpoint_save_dir: "model_checkpoints/best_dice_checkpoint"
  load_checkpoint: # not implemented yet
    load_full_checkpoint: True
    load_model_only: False
    load_checkpoint_path: "model_checkpoints/best_dice_checkpoint"

  load_checkpoint:
    load_full_checkpoint: True        # load model + optimizer + schedulers
    load_model_only: False            # set True if you only want weights
    load_checkpoint_path: "model_checkpoints/best_dice_checkpoint/checkpoint.pt"

# dataset args
dataset_parameters:
  dataset_type: "brats2017_seg"
  train_dataset_args:
    root: "/content/data/brats2017_seg"
    train: True
    # in case you have k-fold train and validation csv 
    fold_id: null
    # for example fold_id: 1 will load train_fold_1.csv
    # default fold_id is null which load train.csv
    # browse to ../../../data/brats2017_seg/brats2017_raw_data/datameta_generator to access to the csv files 
    # and put it under ../../../data/brats2017_seg and change the fold_id accrodingly

  val_dataset_args:
    root: "/content/data/brats2017_seg"
    train: False
    # in case you have k-fold train and validation csv
    fold_id: null
    # for example fold_id: 1 will load validation_fold_1.csv
    # default fold_id is null which load validation.csv
    # browse to ../../../data/brats2017_seg/brats2017_raw_data/datameta_generator to access to the csv files 
    # and put it under ../../../data/brats2017_seg and change the fold_id accrodingly

  train_dataloader_args:
    batch_size: 8 # Initial : 2 // Now : 4 // Colab GPU has enough memory // now : 8 : 12gb/15gb so test with 10 : crash at 10
    shuffle: True
    num_workers: 2 # Initial : 8 // Now : 2 // CPU appears to be bottleneck // 2 is still too slow, test with 1 // test with 3 : killed the process, max is 2
    drop_last: True
    prefetch_factor: 2  # Added to improve dataloader speed, each worker will prefetch 2 batches
    persistent_workers: True  # Added to improve dataloader speed, workers will not be shut down after each epoch

  val_dataloader_args:
    batch_size: 2 # Initial : 1 // Now : 2 // Colab GPU has enough memory
    shuffle: False
    num_workers: 1 # Initial : 6 // Now : 2 // CPU appears to be bottleneck // 2 is still too slow, test with 1
    drop_last: False